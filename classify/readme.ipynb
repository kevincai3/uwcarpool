{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carpooling is a very popular means of long distance transportation for students in Waterloo. However, searching for carpools in the numerous Waterloo Carpool Facebook groups is tedious. This is because all searches must be performed via \"Ctrl f\", all groups must be searched individually, and since only a limited number of posts appear on the page until you scroll down. Thus, we have designed a website to search the following Facebook groups for carpools:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be ideal to be able to search for carpool posts based on whether you are offering or searching for a carpool and the origin, destination and date of the carpool. So we need to develop a method for extracting this information from a post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post, Trips, Groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every post in a Facbook group is referred to as a post and is assigned a unique ID, post_id. A trip is a subset of a post and is determined by a single origin, a single destination, a time, a date and a trinary classification of whether the post is a driving, searching or other post. A driving post is if someone is offering a carpool, a searching post is if someone is searching for a carpool and an other post is an unrelated post. For example, the following post: \"Driving from Waterloo to Toronto at 8:00am and back at 8:00pm today\" contains two trips (Driving from Waterloo to Toronto at 8:00am today & Driving from Toronto to Waterloo at 8:00pm today). Users are given the ability to search for certain trips, and all posts containing those trips are displayed. Each trip is assigned a unique id, trip_id. Only trips from the same post will have the same post_id. These concepts are not enough, however. Since we are extracting information from different Facebook groups, it is possible that numerous groups could both contain the exact same post. When read into the database, this post will appear more than once with different post_ids each time. To deal with this, we introduce groups. A group is a collection of all posts deemed to be duplicates. Each group has a unique group_id. It follows that only posts that are duplicates will have the same group_id and only trips from posts that are duplicates will have the same group_id. Upon searching for trips, having groups allows us to gather duplicates from and display them appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving, Searching and Other Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to discover whether a post is a \"driving\" post (a carpool is being offered), a \"searching\" post (a carpool is being requested) or an \"other\" post (a completetly unrelated post). Discovering whether a post is a driving, searching or an other post is a trinary classification problem, and so we can use a supervised learning algorithm.\n",
    "\n",
    "To do this, however, we need some training data. So we manually classified 1366 posts as driving, searching or other posts. Below is a preview of the data where post_type is the classification and stage_3 is a feature, the processed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from classify.db import engine\n",
    "derived_posts = pd.read_sql_query('SELECT * from derived_posts', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_type</th>\n",
       "      <th>stage_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>driving,waterloo,to,markham,sunday,may,27,at,3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d</td>\n",
       "      <td>driving,toronto,to,waterloo,sunday,may,27th,at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>leaving,waterloo,to,toronto,7pm,today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>driving,scarborough,to,waterloo,at,8am,monday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>driving,fairview,mall,to,waterloo,sunday,may,2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_type                                            stage_3\n",
       "0         d  driving,waterloo,to,markham,sunday,may,27,at,3...\n",
       "1         d  driving,toronto,to,waterloo,sunday,may,27th,at...\n",
       "2         d              leaving,waterloo,to,toronto,7pm,today\n",
       "3         d  driving,scarborough,to,waterloo,at,8am,monday,...\n",
       "4         d  driving,fairview,mall,to,waterloo,sunday,may,2..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_sql_query('SELECT A.post_id, A.post_type, A.route_count, B.stage_3 FROM manual_posts A LEFT JOIN derived_posts B ON (A.post_id = B.post_id) ', con=engine)\n",
    "data[[\"post_type\", \"stage_3\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import string\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_by_comma(x):\n",
    "    return x.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, stage_3 is the only feature. The problem, however, is that stage_3 is a string and cannot be used directly. So we proceed by vectorizing the text. We'll test the TFID, count and 2-gram vectorizers to see which one yields better results. \n",
    "\n",
    "Furthermore, we are going proceed by fitting a random forest model. To choose the hyper parameters we will perform a grid search over the number of estimators as 50,150,300 and the max depth as 60,90, None. The grid search parameters are chosen to given us an idea on how the model results change as we change the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [50, 150,300], 'max_depth': [60,90,None]}\n",
    "gs = GridSearchCV(rf, param, cv = 5, n_jobs = -1, return_train_score= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the TFIDF vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer = split_by_comma)\n",
    "X_tfidf = tfidf_vect.fit_transform(data[\"stage_3\"])\n",
    "X_tfidf_feat = pd.DataFrame(X_tfidf.toarray())\n",
    "X_tfidf_feat.columns = tfidf_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a preview of the TFIDF vectorizer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$10</th>\n",
       "      <th>$15</th>\n",
       "      <th>$150</th>\n",
       "      <th>$20</th>\n",
       "      <th>$20pm</th>\n",
       "      <th>$30</th>\n",
       "      <th>$40</th>\n",
       "      <th>$50</th>\n",
       "      <th>$75</th>\n",
       "      <th>00am</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>workspace</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>writing</th>\n",
       "      <th>wu</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.311852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   $10       $15  $150  $20  $20pm  $30  $40  $50  $75  00am  ...    work  \\\n",
       "0  0.0  0.000000   0.0  0.0    0.0  0.0  0.0  0.0  0.0   0.0  ...     0.0   \n",
       "1  0.0  0.000000   0.0  0.0    0.0  0.0  0.0  0.0  0.0   0.0  ...     0.0   \n",
       "2  0.0  0.000000   0.0  0.0    0.0  0.0  0.0  0.0  0.0   0.0  ...     0.0   \n",
       "3  0.0  0.000000   0.0  0.0    0.0  0.0  0.0  0.0  0.0   0.0  ...     0.0   \n",
       "4  0.0  0.311852   0.0  0.0    0.0  0.0  0.0  0.0  0.0   0.0  ...     0.0   \n",
       "\n",
       "   workspace  world  would  writing   wu  www  year  york  young  \n",
       "0        0.0    0.0    0.0      0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "1        0.0    0.0    0.0      0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "2        0.0    0.0    0.0      0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "3        0.0    0.0    0.0      0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "4        0.0    0.0    0.0      0.0  0.0  0.0   0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 828 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results of the grid search using the TFIDF vectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186291</td>\n",
       "      <td>0.030523</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 50}</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965593</td>\n",
       "      <td>0.009638</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.572471</td>\n",
       "      <td>0.044150</td>\n",
       "      <td>0.017952</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975110</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.093277</td>\n",
       "      <td>0.044281</td>\n",
       "      <td>0.031716</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.191089</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 50}</td>\n",
       "      <td>0.945255</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>0.014686</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.515024</td>\n",
       "      <td>0.023774</td>\n",
       "      <td>0.016955</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.047202</td>\n",
       "      <td>0.029132</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.189694</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.588228</td>\n",
       "      <td>0.042338</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.398865</td>\n",
       "      <td>0.197239</td>\n",
       "      <td>0.033936</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.008721</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.186291      0.030523         0.007586        0.001841   \n",
       "1       0.572471      0.044150         0.017952        0.003025   \n",
       "2       1.093277      0.044281         0.031716        0.001323   \n",
       "3       0.191089      0.004487         0.006582        0.000797   \n",
       "4       0.515024      0.023774         0.016955        0.001410   \n",
       "5       1.047202      0.029132         0.031515        0.005698   \n",
       "6       0.189694      0.007339         0.006582        0.000489   \n",
       "7       0.588228      0.042338         0.020944        0.003888   \n",
       "8       1.398865      0.197239         0.033936        0.005029   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0              60                 50   \n",
       "1              60                150   \n",
       "2              60                300   \n",
       "3              90                 50   \n",
       "4              90                150   \n",
       "5              90                300   \n",
       "6            None                 50   \n",
       "7            None                150   \n",
       "8            None                300   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 60, 'n_estimators': 50}           0.948905   \n",
       "1    {'max_depth': 60, 'n_estimators': 150}           0.956204   \n",
       "2    {'max_depth': 60, 'n_estimators': 300}           0.959854   \n",
       "3     {'max_depth': 90, 'n_estimators': 50}           0.945255   \n",
       "4    {'max_depth': 90, 'n_estimators': 150}           0.959854   \n",
       "5    {'max_depth': 90, 'n_estimators': 300}           0.959854   \n",
       "6   {'max_depth': None, 'n_estimators': 50}           0.959854   \n",
       "7  {'max_depth': None, 'n_estimators': 150}           0.963504   \n",
       "8  {'max_depth': None, 'n_estimators': 300}           0.963504   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.963504           0.970803       ...                0.965593   \n",
       "1           0.974453           0.974453       ...                0.975110   \n",
       "2           0.974453           0.970803       ...                0.974378   \n",
       "3           0.974453           0.978102       ...                0.972914   \n",
       "4           0.970803           0.970803       ...                0.972914   \n",
       "5           0.974453           0.970803       ...                0.973646   \n",
       "6           0.974453           0.970803       ...                0.974378   \n",
       "7           0.974453           0.970803       ...                0.974378   \n",
       "8           0.974453           0.967153       ...                0.973646   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.009638                9                 1.0                 1.0   \n",
       "1        0.010638                1                 1.0                 1.0   \n",
       "2        0.009477                2                 1.0                 1.0   \n",
       "3        0.014686                7                 1.0                 1.0   \n",
       "4        0.008459                7                 1.0                 1.0   \n",
       "5        0.010661                5                 1.0                 1.0   \n",
       "6        0.009477                2                 1.0                 1.0   \n",
       "7        0.008288                2                 1.0                 1.0   \n",
       "8        0.008721                5                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "2                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "5                 1.0                 1.0                 1.0   \n",
       "6                 1.0                 1.0                 1.0   \n",
       "7                 1.0                 1.0                 1.0   \n",
       "8                 1.0                 1.0                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0               1.0              0.0  \n",
       "1               1.0              0.0  \n",
       "2               1.0              0.0  \n",
       "3               1.0              0.0  \n",
       "4               1.0              0.0  \n",
       "5               1.0              0.0  \n",
       "6               1.0              0.0  \n",
       "7               1.0              0.0  \n",
       "8               1.0              0.0  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit_tfidf = gs.fit(X_tfidf_feat, data[\"post_type\"])\n",
    "pd.DataFrame(gs_fit_tfidf.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the count cectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer = split_by_comma)\n",
    "X_count = count_vect.fit_transform(data[\"stage_3\"])\n",
    "X_count_feat= pd.DataFrame(X_count.toarray())\n",
    "X_count_feat.columns = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a preview of the count vectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$10</th>\n",
       "      <th>$15</th>\n",
       "      <th>$150</th>\n",
       "      <th>$20</th>\n",
       "      <th>$20pm</th>\n",
       "      <th>$30</th>\n",
       "      <th>$40</th>\n",
       "      <th>$50</th>\n",
       "      <th>$75</th>\n",
       "      <th>00am</th>\n",
       "      <th>...</th>\n",
       "      <th>work</th>\n",
       "      <th>workspace</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>writing</th>\n",
       "      <th>wu</th>\n",
       "      <th>www</th>\n",
       "      <th>year</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   $10  $15  $150  $20  $20pm  $30  $40  $50  $75  00am  ...    work  \\\n",
       "0    0    0     0    0      0    0    0    0    0     0  ...       0   \n",
       "1    0    0     0    0      0    0    0    0    0     0  ...       0   \n",
       "2    0    0     0    0      0    0    0    0    0     0  ...       0   \n",
       "3    0    0     0    0      0    0    0    0    0     0  ...       0   \n",
       "4    0    1     0    0      0    0    0    0    0     0  ...       0   \n",
       "\n",
       "   workspace  world  would  writing  wu  www  year  york  young  \n",
       "0          0      0      0        0   0    0     0     0      0  \n",
       "1          0      0      0        0   0    0     0     0      0  \n",
       "2          0      0      0        0   0    0     0     0      0  \n",
       "3          0      0      0        0   0    0     0     0      0  \n",
       "4          0      0      0        0   0    0     0     0      0  \n",
       "\n",
       "[5 rows x 828 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results of the grid search using the count vectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220907</td>\n",
       "      <td>0.053369</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 50}</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969253</td>\n",
       "      <td>0.009360</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785808</td>\n",
       "      <td>0.052026</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.431239</td>\n",
       "      <td>0.031272</td>\n",
       "      <td>0.051969</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.254686</td>\n",
       "      <td>0.027499</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 50}</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973646</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.715884</td>\n",
       "      <td>0.025674</td>\n",
       "      <td>0.030915</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976574</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.630293</td>\n",
       "      <td>0.159672</td>\n",
       "      <td>0.058643</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978038</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.035573</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974378</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.788559</td>\n",
       "      <td>0.043687</td>\n",
       "      <td>0.025175</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.974453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972914</td>\n",
       "      <td>0.008134</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.615574</td>\n",
       "      <td>0.182188</td>\n",
       "      <td>0.049573</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.970803</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975842</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.220907      0.053369         0.011072        0.005518   \n",
       "1       0.785808      0.052026         0.024754        0.003167   \n",
       "2       1.431239      0.031272         0.051969        0.005537   \n",
       "3       0.254686      0.027499         0.010693        0.002721   \n",
       "4       0.715884      0.025674         0.030915        0.009290   \n",
       "5       1.630293      0.159672         0.058643        0.020277   \n",
       "6       0.316553      0.035573         0.011171        0.003858   \n",
       "7       0.788559      0.043687         0.025175        0.003059   \n",
       "8       1.615574      0.182188         0.049573        0.017398   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0              60                 50   \n",
       "1              60                150   \n",
       "2              60                300   \n",
       "3              90                 50   \n",
       "4              90                150   \n",
       "5              90                300   \n",
       "6            None                 50   \n",
       "7            None                150   \n",
       "8            None                300   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 60, 'n_estimators': 50}           0.959854   \n",
       "1    {'max_depth': 60, 'n_estimators': 150}           0.967153   \n",
       "2    {'max_depth': 60, 'n_estimators': 300}           0.967153   \n",
       "3     {'max_depth': 90, 'n_estimators': 50}           0.967153   \n",
       "4    {'max_depth': 90, 'n_estimators': 150}           0.974453   \n",
       "5    {'max_depth': 90, 'n_estimators': 300}           0.970803   \n",
       "6   {'max_depth': None, 'n_estimators': 50}           0.967153   \n",
       "7  {'max_depth': None, 'n_estimators': 150}           0.963504   \n",
       "8  {'max_depth': None, 'n_estimators': 300}           0.970803   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.956204           0.978102       ...                0.969253   \n",
       "1           0.970803           0.970803       ...                0.973646   \n",
       "2           0.963504           0.970803       ...                0.972914   \n",
       "3           0.963504           0.970803       ...                0.973646   \n",
       "4           0.963504           0.974453       ...                0.976574   \n",
       "5           0.970803           0.974453       ...                0.978038   \n",
       "6           0.970803           0.970803       ...                0.974378   \n",
       "7           0.963504           0.974453       ...                0.972914   \n",
       "8           0.967153           0.978102       ...                0.975842   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.009360                9                 1.0                 1.0   \n",
       "1        0.005294                5                 1.0                 1.0   \n",
       "2        0.007802                7                 1.0                 1.0   \n",
       "3        0.008389                5                 1.0                 1.0   \n",
       "4        0.008470                2                 1.0                 1.0   \n",
       "5        0.007607                1                 1.0                 1.0   \n",
       "6        0.006039                4                 1.0                 1.0   \n",
       "7        0.008134                7                 1.0                 1.0   \n",
       "8        0.006319                3                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 1.0            1.000000                 1.0   \n",
       "1                 1.0            1.000000                 1.0   \n",
       "2                 1.0            1.000000                 1.0   \n",
       "3                 1.0            0.999086                 1.0   \n",
       "4                 1.0            1.000000                 1.0   \n",
       "5                 1.0            1.000000                 1.0   \n",
       "6                 1.0            1.000000                 1.0   \n",
       "7                 1.0            1.000000                 1.0   \n",
       "8                 1.0            1.000000                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          1.000000         0.000000  \n",
       "1          1.000000         0.000000  \n",
       "2          1.000000         0.000000  \n",
       "3          0.999817         0.000366  \n",
       "4          1.000000         0.000000  \n",
       "5          1.000000         0.000000  \n",
       "6          1.000000         0.000000  \n",
       "7          1.000000         0.000000  \n",
       "8          1.000000         0.000000  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit_count = gs.fit(X_count_feat, data[\"post_type\"])\n",
    "pd.DataFrame(gs_fit_count.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the 2-Gram vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting tockenized sentence back into a sentence with spaces for ngrams\n",
    "data_ngram = data[\"stage_3\"].apply(lambda x: x.replace(\",\",\" \"))\n",
    "\n",
    "gram2_vect = CountVectorizer(ngram_range = (2,2))\n",
    "X_gram2 = gram2_vect.fit_transform(data_ngram)\n",
    "X_gram2_feat= pd.DataFrame(X_gram2.toarray())\n",
    "X_gram2_feat.columns = gram2_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a preview of the 2-gram vectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00 25</th>\n",
       "      <th>00 27</th>\n",
       "      <th>00 door</th>\n",
       "      <th>00 message</th>\n",
       "      <th>00 northyork</th>\n",
       "      <th>00 thursday</th>\n",
       "      <th>00 today</th>\n",
       "      <th>00am 20</th>\n",
       "      <th>00am 24</th>\n",
       "      <th>00am back</th>\n",
       "      <th>...</th>\n",
       "      <th>york scarborough</th>\n",
       "      <th>york station</th>\n",
       "      <th>york to</th>\n",
       "      <th>york today</th>\n",
       "      <th>york tomorrow</th>\n",
       "      <th>york tonight</th>\n",
       "      <th>york toronto</th>\n",
       "      <th>york waterloo</th>\n",
       "      <th>york york</th>\n",
       "      <th>young clinton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3935 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00 25  00 27  00 door  00 message  00 northyork  00 thursday  00 today  \\\n",
       "0      0      0        0           0             0            0         0   \n",
       "1      0      0        0           0             0            0         0   \n",
       "2      0      0        0           0             0            0         0   \n",
       "3      0      0        0           0             0            0         0   \n",
       "4      0      0        0           0             0            0         0   \n",
       "\n",
       "   00am 20  00am 24  00am back      ...        york scarborough  york station  \\\n",
       "0        0        0          0      ...                       0             0   \n",
       "1        0        0          0      ...                       0             0   \n",
       "2        0        0          0      ...                       0             0   \n",
       "3        0        0          0      ...                       0             0   \n",
       "4        0        0          0      ...                       0             0   \n",
       "\n",
       "   york to  york today  york tomorrow  york tonight  york toronto  \\\n",
       "0        0           0              0             0             0   \n",
       "1        0           0              0             0             0   \n",
       "2        0           0              0             0             0   \n",
       "3        0           0              0             0             0   \n",
       "4        0           0              0             0             0   \n",
       "\n",
       "   york waterloo  york york  young clinton  \n",
       "0              0          0              0  \n",
       "1              0          0              0  \n",
       "2              0          0              0  \n",
       "3              0          0              0  \n",
       "4              0          0              0  \n",
       "\n",
       "[5 rows x 3935 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_gram2_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the results of the grid search using the 2-gram vectorizer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.958746</td>\n",
       "      <td>0.282798</td>\n",
       "      <td>0.021765</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 50}</td>\n",
       "      <td>0.945255</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953148</td>\n",
       "      <td>0.012830</td>\n",
       "      <td>4</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.997804</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.047605</td>\n",
       "      <td>0.280491</td>\n",
       "      <td>0.056336</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.930657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.016636</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.998172</td>\n",
       "      <td>0.999085</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.638615</td>\n",
       "      <td>0.155951</td>\n",
       "      <td>0.116456</td>\n",
       "      <td>0.008277</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952416</td>\n",
       "      <td>0.016220</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.564484</td>\n",
       "      <td>0.041508</td>\n",
       "      <td>0.028568</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 50}</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.941606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956076</td>\n",
       "      <td>0.013939</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.665439</td>\n",
       "      <td>0.372282</td>\n",
       "      <td>0.073367</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.937956</td>\n",
       "      <td>0.956204</td>\n",
       "      <td>0.937956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956076</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.469072</td>\n",
       "      <td>0.498171</td>\n",
       "      <td>0.130874</td>\n",
       "      <td>0.016524</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953148</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.531452</td>\n",
       "      <td>0.127608</td>\n",
       "      <td>0.026161</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>None</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 50}</td>\n",
       "      <td>0.948905</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.014077</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.984835</td>\n",
       "      <td>0.051413</td>\n",
       "      <td>0.057766</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>0.959854</td>\n",
       "      <td>0.930657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.865542</td>\n",
       "      <td>1.301235</td>\n",
       "      <td>0.087867</td>\n",
       "      <td>0.035483</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.930657</td>\n",
       "      <td>0.952555</td>\n",
       "      <td>0.934307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950220</td>\n",
       "      <td>0.016160</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.958746      0.282798         0.021765        0.004120   \n",
       "1       4.047605      0.280491         0.056336        0.003915   \n",
       "2       8.638615      0.155951         0.116456        0.008277   \n",
       "3       1.564484      0.041508         0.028568        0.003620   \n",
       "4       4.665439      0.372282         0.073367        0.013434   \n",
       "5       8.469072      0.498171         0.130874        0.016524   \n",
       "6       1.531452      0.127608         0.026161        0.007925   \n",
       "7       3.984835      0.051413         0.057766        0.005021   \n",
       "8       6.865542      1.301235         0.087867        0.035483   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0              60                 50   \n",
       "1              60                150   \n",
       "2              60                300   \n",
       "3              90                 50   \n",
       "4              90                150   \n",
       "5              90                300   \n",
       "6            None                 50   \n",
       "7            None                150   \n",
       "8            None                300   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0     {'max_depth': 60, 'n_estimators': 50}           0.945255   \n",
       "1    {'max_depth': 60, 'n_estimators': 150}           0.934307   \n",
       "2    {'max_depth': 60, 'n_estimators': 300}           0.934307   \n",
       "3     {'max_depth': 90, 'n_estimators': 50}           0.941606   \n",
       "4    {'max_depth': 90, 'n_estimators': 150}           0.937956   \n",
       "5    {'max_depth': 90, 'n_estimators': 300}           0.934307   \n",
       "6   {'max_depth': None, 'n_estimators': 50}           0.948905   \n",
       "7  {'max_depth': None, 'n_estimators': 150}           0.934307   \n",
       "8  {'max_depth': None, 'n_estimators': 300}           0.930657   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.952555           0.934307       ...                0.953148   \n",
       "1           0.948905           0.930657       ...                0.950220   \n",
       "2           0.952555           0.934307       ...                0.952416   \n",
       "3           0.952555           0.941606       ...                0.956076   \n",
       "4           0.956204           0.937956       ...                0.956076   \n",
       "5           0.952555           0.934307       ...                0.953148   \n",
       "6           0.963504           0.934307       ...                0.957540   \n",
       "7           0.959854           0.930657       ...                0.950220   \n",
       "8           0.952555           0.934307       ...                0.950220   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.012830                4            0.997253            0.998168   \n",
       "1        0.016636                7            0.999084            0.999084   \n",
       "2        0.016220                6            0.999084            0.999084   \n",
       "3        0.013939                2            1.000000            1.000000   \n",
       "4        0.016882                2            1.000000            1.000000   \n",
       "5        0.017083                4            1.000000            1.000000   \n",
       "6        0.014077                1            0.999084            1.000000   \n",
       "7        0.014799                7            1.000000            1.000000   \n",
       "8        0.016160                7            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.999084            0.997258            0.997258   \n",
       "1            1.000000            0.999086            0.998172   \n",
       "2            1.000000            0.999086            0.999086   \n",
       "3            1.000000            1.000000            1.000000   \n",
       "4            1.000000            1.000000            1.000000   \n",
       "5            1.000000            1.000000            1.000000   \n",
       "6            1.000000            1.000000            1.000000   \n",
       "7            1.000000            1.000000            1.000000   \n",
       "8            1.000000            1.000000            1.000000   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.997804         0.000731  \n",
       "1          0.999085         0.000578  \n",
       "2          0.999268         0.000366  \n",
       "3          1.000000         0.000000  \n",
       "4          1.000000         0.000000  \n",
       "5          1.000000         0.000000  \n",
       "6          0.999817         0.000366  \n",
       "7          1.000000         0.000000  \n",
       "8          1.000000         0.000000  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_fit_gram2 = gs.fit(X_gram2_feat, data[\"post_type\"])\n",
    "pd.DataFrame(gs_fit_gram2.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since the plan is to classify posts on an hourly basis, the classification time is unimportant, so we ignore the score time. The mean test score score is essentially 97% for both the TFIDF and count vectorizers and essentially 95% for the 2-gram vectorizer. Since there is hardly any difference in the test score between different hyper parameters, we choose the simplest model which is the count vectorizer with 50 estimators and a max depth of 60. We could continue further with tuning the hyper parameters or try different models, however, the results are satisfactory so we stop here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 60, max_depth = 10, n_jobs=-1).fit(X_count_feat,data[\"post_type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the nice things about a random forest model is that we can see the importance of every feature. The top 10 most important features of our chosen model (for the count vectorizer the features are individual words) are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['looking',\n",
       " 'ride',\n",
       " 'driving',\n",
       " '$15',\n",
       " 'waterloo',\n",
       " 'at',\n",
       " 'from',\n",
       " 'anytime',\n",
       " 'anyone',\n",
       " 'text']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[1] for x in sorted(zip(model.feature_importances_, count_vect.get_feature_names()), reverse = True)[0:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words \"looking\" and \"driving\" are the most important, which is no surprise. However, \"$15\" is also an important feature. This is probably because people offering rides are usually the ones who name prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Detection:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words \"to\" and \"from\" are words commonly used in carpooling posts, or so I suspect. Lets see the percentage of posts which contain the word \"to\" or the word \"from\" from our batch of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692338694560042"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for x in derived_posts[\"stage_3\"].tolist() if (\"to\" or \"from\") in split_by_comma(x)])/derived_posts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More than 95% of the posts contain the words \"to\" and \"from\". And so we can use the relative location of cities in the post, in terms of the words \"to\" and \"from\", to determine the origins and destinations of the trips in the post. For posts with 1 trip, or posts with multiple trips in which the words “to” and/or “from” only appear once (for example “Driving from Waterloo to Mississauga then Toronto”) this method is almost flawless. However, for other posts, this method only successfully finds the first trip. Approximately 700 if the previously classified posts have been manually counted for their number of routes. So let see the percentage of the counted posts that have 1 trip are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8349120433017592"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for x in data.dropna()[\"route_count\"] if x == 1])/data.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So using our sample, we conclude that approximately 83% of posts have 1 trip. Due to the high percentage this method of route detection is viable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
