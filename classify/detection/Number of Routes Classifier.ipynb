{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carpool_data import posts, derived_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first feature will be character count of the original post, transformed\n",
    "posts[\"post_length\"] = posts[\"message\"].apply(lambda x: len(x))\n",
    "posts[\"length_transformed\"] = scipy.stats.boxcox(posts[\"post_length\"])[0]\n",
    "\n",
    "#2nd feature will be number of capitals, transformed\n",
    "def num_of_caps(string):\n",
    "    return sum(1 for c in string if c.isupper())\n",
    "\n",
    "posts[\"number_of_caps\"] = posts[\"message\"].apply(lambda x: num_of_caps(x))\n",
    "posts[\"caps_transformed\"] = scipy.stats.boxcox(posts[\"number_of_caps\"] + 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing the data (count vectorization)\n",
    "def split_by_comma(x):\n",
    "    return x.split(\",\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "count_vect = CountVectorizer(analyzer = split_by_comma)\n",
    "\n",
    "#the training set of posts for number of routes\n",
    "#in particular, the classified posts for number of routes\n",
    "posts_tr_routes = posts[~posts[\"number_of_routes\"].isnull()].reset_index(drop = True)\n",
    "\n",
    "X_count = count_vect.fit_transform(posts_tr_routes[\"tockenized_message\"])\n",
    "X_count_feat = pd.DataFrame(X_count.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the features to the document turn matrix\n",
    "#once again this is only for the classified ones\n",
    "X_count_feat[\"length_transformed\"] = posts_tr_routes[\"length_transformed\"]\n",
    "X_count_feat[\"caps_transformed\"] = posts_tr_routes[\"caps_transformed\"]\n",
    "Y = posts_tr_routes[\"number_of_routes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10,150,300], 'max_depth': [60,90,None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027468</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0.998311</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>0.996616</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.994941</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>7.599754e-04</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.368774</td>\n",
       "      <td>0.015249</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925676</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094724</td>\n",
       "      <td>3.125245e-03</td>\n",
       "      <td>0.022333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.920049</td>\n",
       "      <td>0.033490</td>\n",
       "      <td>0.944520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>1.022554e-03</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042313</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.996604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.998308</td>\n",
       "      <td>0.965753</td>\n",
       "      <td>0.994941</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>4.006627e-04</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467444</td>\n",
       "      <td>0.021858</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011578</td>\n",
       "      <td>8.155662e-03</td>\n",
       "      <td>0.020249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.891573</td>\n",
       "      <td>0.034491</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>2.877854e-03</td>\n",
       "      <td>0.021365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.038102</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.929635</td>\n",
       "      <td>0.994930</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.996604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.991540</td>\n",
       "      <td>0.952055</td>\n",
       "      <td>0.993255</td>\n",
       "      <td>0.951724</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>3.989506e-07</td>\n",
       "      <td>0.018546</td>\n",
       "      <td>0.002386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.436962</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.943166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015198</td>\n",
       "      <td>1.022611e-03</td>\n",
       "      <td>0.022194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.766440</td>\n",
       "      <td>0.020662</td>\n",
       "      <td>0.944520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.932432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038855</td>\n",
       "      <td>1.211400e-03</td>\n",
       "      <td>0.020470</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.027468         0.002795         0.932341          0.998311   \n",
       "1       0.368774         0.015249         0.939107          1.000000   \n",
       "2       0.920049         0.033490         0.944520          1.000000   \n",
       "3       0.042313         0.003207         0.939107          0.996961   \n",
       "4       0.467444         0.021858         0.939107          1.000000   \n",
       "5       0.891573         0.034491         0.943166          1.000000   \n",
       "6       0.038102         0.003008         0.929635          0.994930   \n",
       "7       0.436962         0.016643         0.943166          1.000000   \n",
       "8       0.766440         0.020662         0.944520          1.000000   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0              60                 10   \n",
       "1              60                150   \n",
       "2              60                300   \n",
       "3              90                 10   \n",
       "4              90                150   \n",
       "5              90                300   \n",
       "6            None                 10   \n",
       "7            None                150   \n",
       "8            None                300   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "0     {'max_depth': 60, 'n_estimators': 10}                8   \n",
       "1    {'max_depth': 60, 'n_estimators': 150}                5   \n",
       "2    {'max_depth': 60, 'n_estimators': 300}                1   \n",
       "3     {'max_depth': 90, 'n_estimators': 10}                5   \n",
       "4    {'max_depth': 90, 'n_estimators': 150}                5   \n",
       "5    {'max_depth': 90, 'n_estimators': 300}                3   \n",
       "6   {'max_depth': None, 'n_estimators': 10}                9   \n",
       "7  {'max_depth': None, 'n_estimators': 150}                3   \n",
       "8  {'max_depth': None, 'n_estimators': 300}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0           0.906667            1.000000       ...                  0.932432   \n",
       "1           0.926667            1.000000       ...                  0.925676   \n",
       "2           0.926667            1.000000       ...                  0.939189   \n",
       "3           0.920000            0.996604       ...                  0.945946   \n",
       "4           0.920000            1.000000       ...                  0.932432   \n",
       "5           0.926667            1.000000       ...                  0.932432   \n",
       "6           0.906667            0.996604       ...                  0.918919   \n",
       "7           0.933333            1.000000       ...                  0.932432   \n",
       "8           0.933333            1.000000       ...                  0.932432   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.996616           0.965753            0.994941   \n",
       "1            1.000000           0.972603            1.000000   \n",
       "2            1.000000           0.972603            1.000000   \n",
       "3            0.998308           0.965753            0.994941   \n",
       "4            1.000000           0.972603            1.000000   \n",
       "5            1.000000           0.972603            1.000000   \n",
       "6            0.991540           0.952055            0.993255   \n",
       "7            1.000000           0.972603            1.000000   \n",
       "8            1.000000           0.972603            1.000000   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.958621            1.000000      0.004988    7.599754e-04   \n",
       "1           0.958621            1.000000      0.094724    3.125245e-03   \n",
       "2           0.965517            1.000000      0.007730    1.022554e-03   \n",
       "3           0.965517            0.994949      0.002719    4.006627e-04   \n",
       "4           0.951724            1.000000      0.011578    8.155662e-03   \n",
       "5           0.965517            1.000000      0.021217    2.877854e-03   \n",
       "6           0.951724            0.994949      0.001269    3.989506e-07   \n",
       "7           0.965517            1.000000      0.015198    1.022611e-03   \n",
       "8           0.965517            1.000000      0.038855    1.211400e-03   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.026498         0.002135  \n",
       "1        0.022333         0.000000  \n",
       "2        0.020850         0.000000  \n",
       "3        0.025904         0.001965  \n",
       "4        0.020249         0.000000  \n",
       "5        0.021365         0.000000  \n",
       "6        0.018546         0.002386  \n",
       "7        0.022194         0.000000  \n",
       "8        0.020470         0.000000  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = GridSearchCV(rf, param, cv = 5, n_jobs = -1, return_train_score= True)\n",
    "gs_fit = gs.fit(X_count_feat, Y)\n",
    "pd.DataFrame(gs_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026067</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.945873</td>\n",
       "      <td>0.997294</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 10}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.946309</td>\n",
       "      <td>0.994915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.998311</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>4.974850e-04</td>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390430</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.953992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 150}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138458</td>\n",
       "      <td>3.760747e-03</td>\n",
       "      <td>0.027962</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.064231</td>\n",
       "      <td>0.043516</td>\n",
       "      <td>0.953992</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 60, 'n_estimators': 300}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.106097</td>\n",
       "      <td>1.237203e-02</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.040508</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.941813</td>\n",
       "      <td>0.995601</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.926174</td>\n",
       "      <td>0.993220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.994932</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>4.015452e-04</td>\n",
       "      <td>0.038154</td>\n",
       "      <td>0.001358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500331</td>\n",
       "      <td>0.019051</td>\n",
       "      <td>0.947226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043191</td>\n",
       "      <td>1.677844e-03</td>\n",
       "      <td>0.037827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.898188</td>\n",
       "      <td>0.031484</td>\n",
       "      <td>0.951286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045319</td>\n",
       "      <td>1.022508e-03</td>\n",
       "      <td>0.038302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050936</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>0.996279</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.926174</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945578</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.998311</td>\n",
       "      <td>0.925170</td>\n",
       "      <td>0.996622</td>\n",
       "      <td>0.008205</td>\n",
       "      <td>8.869684e-07</td>\n",
       "      <td>0.038882</td>\n",
       "      <td>0.001971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.431748</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>0.952639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.959732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965986</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024227</td>\n",
       "      <td>1.022536e-03</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.764033</td>\n",
       "      <td>0.024665</td>\n",
       "      <td>0.945873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.953020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037559</td>\n",
       "      <td>3.509006e-03</td>\n",
       "      <td>0.039176</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.026067         0.002399         0.945873          0.997294   \n",
       "1       0.390430         0.015031         0.953992          1.000000   \n",
       "2       1.064231         0.043516         0.953992          1.000000   \n",
       "3       0.040508         0.003208         0.941813          0.995601   \n",
       "4       0.500331         0.019051         0.947226          1.000000   \n",
       "5       0.898188         0.031484         0.951286          1.000000   \n",
       "6       0.050936         0.003008         0.932341          0.996279   \n",
       "7       0.431748         0.017646         0.952639          1.000000   \n",
       "8       0.764033         0.024665         0.945873          1.000000   \n",
       "\n",
       "  param_max_depth param_n_estimators  \\\n",
       "0              60                 10   \n",
       "1              60                150   \n",
       "2              60                300   \n",
       "3              90                 10   \n",
       "4              90                150   \n",
       "5              90                300   \n",
       "6            None                 10   \n",
       "7            None                150   \n",
       "8            None                300   \n",
       "\n",
       "                                     params  rank_test_score  \\\n",
       "0     {'max_depth': 60, 'n_estimators': 10}                6   \n",
       "1    {'max_depth': 60, 'n_estimators': 150}                1   \n",
       "2    {'max_depth': 60, 'n_estimators': 300}                1   \n",
       "3     {'max_depth': 90, 'n_estimators': 10}                8   \n",
       "4    {'max_depth': 90, 'n_estimators': 150}                5   \n",
       "5    {'max_depth': 90, 'n_estimators': 300}                4   \n",
       "6   {'max_depth': None, 'n_estimators': 10}                9   \n",
       "7  {'max_depth': None, 'n_estimators': 150}                3   \n",
       "8  {'max_depth': None, 'n_estimators': 300}                6   \n",
       "\n",
       "   split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "0           0.946309            0.994915       ...                  0.938776   \n",
       "1           0.959732            1.000000       ...                  0.952381   \n",
       "2           0.966443            1.000000       ...                  0.952381   \n",
       "3           0.926174            0.993220       ...                  0.918367   \n",
       "4           0.953020            1.000000       ...                  0.945578   \n",
       "5           0.959732            1.000000       ...                  0.959184   \n",
       "6           0.926174            0.998305       ...                  0.945578   \n",
       "7           0.959732            1.000000       ...                  0.952381   \n",
       "8           0.953020            1.000000       ...                  0.931973   \n",
       "\n",
       "   split2_train_score  split3_test_score  split3_train_score  \\\n",
       "0            0.996622           0.993197            0.996622   \n",
       "1            1.000000           0.993197            1.000000   \n",
       "2            1.000000           0.993197            1.000000   \n",
       "3            0.996622           0.993197            0.994932   \n",
       "4            1.000000           0.993197            1.000000   \n",
       "5            1.000000           0.993197            1.000000   \n",
       "6            0.993243           0.993197            0.998311   \n",
       "7            1.000000           1.000000            1.000000   \n",
       "8            1.000000           0.993197            1.000000   \n",
       "\n",
       "   split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "0           0.959184            0.998311      0.001692    4.974850e-04   \n",
       "1           0.959184            1.000000      0.138458    3.760747e-03   \n",
       "2           0.972789            1.000000      0.106097    1.237203e-02   \n",
       "3           0.979592            0.996622      0.002423    4.015452e-04   \n",
       "4           0.965986            1.000000      0.043191    1.677844e-03   \n",
       "5           0.965986            1.000000      0.045319    1.022508e-03   \n",
       "6           0.925170            0.996622      0.008205    8.869684e-07   \n",
       "7           0.965986            1.000000      0.024227    1.022536e-03   \n",
       "8           0.972789            1.000000      0.037559    3.509006e-03   \n",
       "\n",
       "   std_test_score  std_train_score  \n",
       "0        0.032598         0.001727  \n",
       "1        0.027962         0.000000  \n",
       "2        0.036640         0.000000  \n",
       "3        0.038154         0.001358  \n",
       "4        0.037827         0.000000  \n",
       "5        0.038302         0.000000  \n",
       "6        0.038882         0.001971  \n",
       "7        0.037278         0.000000  \n",
       "8        0.039176         0.000000  \n",
       "\n",
       "[9 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#since we dont have enough manual classifications,\n",
    "#we will just differentiate between 1 and more than 1 route\n",
    "Y2 = [0] * len(Y)\n",
    "for i  in range(0,len(Y)):\n",
    "    if(Y[i] > 1):\n",
    "        Y2[i] = 2    \n",
    "    else:\n",
    "        Y2[i] = 1 \n",
    "\n",
    "gs_fit = gs.fit(X_count_feat, Y2)\n",
    "pd.DataFrame(gs_fit.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_count2 = count_vect.fit(posts_tr_routes[\"tockenized_message\"])\n",
    "mes = \"Test\"\n",
    "c = X_count2.transform([mes])\n",
    "print(c)\n",
    "#need to add the other 2 features into this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x247bde0b828>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247bddff320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a look at the distributions\n",
    "posts[\"post_length\"].hist(bins = 100)\n",
    "posts[\"number_of_caps\"].hist(bins = 50)\n",
    "posts[\"length_transformed\"].hist(bins=50)\n",
    "posts[\"caps_transformed\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
